<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="static/assets/newsish-fav.png">
  <title>News-ish</title>
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

  <!-- D3 Import -->
  <script src="https://d3js.org/d3.v5.min.js"></script>   

  <!-- Our CSS -->
  <link rel="stylesheet" type="text/css" href="static/css/style.css">

</head>

<body>
  <div class="container" id="top">
    <div class="row">
        <div class="col-4"></div>
        <div class="col-1 menu-right"><a href="about.html">about</a></div>
        <div class="col-2">
            <h3 class="header-row"><a href="index.html">News-<i>ish</i></h3></a>
        </div>
        <div class="col-1 menu-right"><a href="team.html">team</a></div>
    </div>
    <hr>
</div>   

<div class="container">
    <div class="row">
        <!-- PROJECT DESCRIPTION SECTION -->
        <div class="col-12" id="project-description-section"><h2 class="centered">Project Description</h2><hr></div>
        <div class="col-12"><h6 class="article thin">&emsp;This project is a machine learning exercise in which we used an NLP classification model to determine whether a news article is considered a reliable source of information. The model implements a Multinomial Naïve Bayes algorithm to predict these news sources as “reliable”  or “unreliable”. The process started by exploring the data, preprocessing the model input, training the model and testing it. Finally, we developed a website that features a user input form on our home page in which you can paste your own article to determine whether it is a reliable information source.</h6><br></div>


        <!-- DATA EXPLORATION SECTION -->
        <div class="col-12" id="data-exploration-section"><h2 class="centered">Data Exploration</h2><hr></div>
        <div class="col-12"><h6 class="article thin">&emsp;During the exploratory stages of the  project, we used WordCloud to visualize the most common words used in the determined “unreliable” and “reliable” articles to see which topics are common targets of both determinations.</h6><br><br></div>
        <div class="col-6">
            <img class="centered-img" src="static/assets/reliable.jpg" alt="reliable word cloud">
            <h5 class="centered padding">Reliable Word Cloud</h5>
        </div>
        <div class="col-6">
            <img class="centered-img" src="static/assets/unreliable.jpg" alt="unreliable word cloud">
            <h5 class="centered padding">Unreliable Word Cloud</h5>
        </div>
        <div class="col-12"><h6 class="centered"><a href="about.html#top">BACK TO TOP</a><br><br><br></h6></div>

        <!-- PREPROCESSING SECTION -->
        <div class="col-12" id="preprocessing-section"><h2 class="centered">Preprocessing</h2><hr></div>
        <div class="col-12"><h6 class="article thin">&emsp;The data was preprocessed by making it suitable for building and training the model. We considered the standard process like converting the text to lower case and removal of special characters, and other additional steps like the use of regular expressions for the removal of possessive and contractions. Part of this process was performed by the vectorizer built-in tokenizer and stop-words removal, simplifying the code and the running time.</h6><br></div>
        <img class="centered-img padding" src="../static/assets/vectorizer.jpg" alt="vectorizer from jupyter notebook">
        <div class="col-12"><h6 class="centered"><a href="about.html#top">BACK TO TOP</a><br><br></h6></div>

        <!-- NAÏVE BAYES SECTION -->
        <div class="col-12" id="naive-bayes-section"><h2 class="centered">Naïve Bayes Model</h2><hr></div>
        <div class="col-12"><h6 class="article thin">&emsp;A classifier is a machine learning model that is used to discriminate different  objects based on certain features. A Naive Bayes (NB) classifier is a probabilistic machine learning model that’s used for classification task (1).  An NB classifier is noted for being a fast algorithm and fairly accurate when predicting natural language processing (NLP) problems. This project is an NLP problem where we used NB to predict whether a news article can be classified as “reliable” or “unreliable”, based on certain texts pertaining to their respective “tag words”. <br><br>
            &emsp;NB combines both probability and Bayes’ Theorem to predict the outcome of a text, then categorizes it to a tag word. A good example of Naïve Bayes classification is categorizing emails into “Primary” or “Spam” inboxes based on the text of the email. To put Naïve Bayes simply, “tag words” is synonymous with “categories” and we are trying to decipher snippets of text that can be put into these categories. In this project the texts used for the model training were the title and the body of the article separately, as well as the combination of both plus the authors, to explore the different outcomes and accuracy. The best output was achieved by the combination of the three fields, title + author + text.<br><br>
            For more information visit: <a href="https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c">Towards Data Science</a>
        <div class="col-12"><h6 class="centered"><a href="about.html#top">BACK TO TOP</a><br><br></h6></div>

            <!-- MATRIX SECTION -->
        <div class="col-12" id="matrix-section"><h2 class="centered">Confusion Matrix & Classification Report</h2><hr></div>
        <div class="col-12"><h6 class="article thin">A confusion matrix is a way of testing the performance of a classification algorithm, in our case, we used the confusion matrix to summarize whether our Naïve Bayes classification was performing the way we wanted. We know that from our dataset that there are two classes: “reliable” and “unreliable”, so we used the confusion matrix for a binary classifier, as there are only two predicted classes. Since there are two classes for our project, the 4 quadrants of the confusion matrix model are as follows: True Positives (TP), True Negatives (TN), False Positives (FP) & False Negatives (FN). <br><br> The quadrants are described as: 
            <ul>
                <li>True Positives (TP): News articles we predicted as “reliable” and they turned out to be “reliable”</li>
                <li>True Negatives (TN): News articles we predicted as “unreliable” and they turned out to be “unreliable”</li>
                <li>False Positives (FP): News articles we predicted as “reliable” and they turned out to be “unreliable”</li>
                <li>False Negatives (FN): News articles we predicted as “unreliable” and they turned out to be “reliable”</li>
            </ul>
            </h6>
        </div>

        <div class="col-md-6">
                <img class="centered-img-sbs" src="static/assets/trainingdata-matrix.jpg" alt="training data matrix">
                <h5 class="centered padding">Matrix : Training Data</h5>
        </div>
        <div class="col-md-6">
                <img class="centered-img-sbs" src="static/assets/testdata-matrix.jpg" alt="test data matrix">
                <h5 class="centered padding">Matrix : Test Data</h5>
        </div>

        <div class="col-md-12">
            <br>
            <img class="centered-img padding" src="static/assets/matrix-desc.jpg" alt="matrix description">
        </div>

        <div class="col-12"><h6 class="article thin"><br>&emsp;Following the training data, the model correctly identified 7,300 “reliable” and 5,500 “unreliable” news items out of approximately 12,518 in the set.  With the test data, the model predicted 3,100 “reliable” and 2,100 “unreliable” news items out of approximately 5,500 in the set.<br><br>
            <ul>
                <li>Precision: 99% of predictions of “unreliable” news were accurate, while 92% of predictions of “reliable” news were accurate.<br></li>
                <li>Recall: 99% of “reliable” items were correctly predicted, while 89% of “unreliable” items were correctly predicted.<br></li>
                <li>F1 Score: The harmonic average of Precision and Recall provided an F1 Score of 95%.<br></li>
                <li>Accuracy: Overall, 95% of the predictions made were correct.</li>
            </ul>
                    <br></h6></div>
        <div class="col-12"><h6 class="centered"><a href="about.html#top">BACK TO TOP</a><br><br><br></h6></div>

        <!-- NEXT STEPS SECTION -->
        <div class="col-12" id="analysis-section"><h2 class="centered">Analysis</h2><hr></div>
        <div class="col-12"><h6 class="article thin"><br>&emsp;After building and running our model - the percentage of accuracy was very high (~95% accurate). While scoring high, we realized that the model was more accurately to be described as a 'spam filter', rather - a text is "reliable" if it comes from a source that is able to type in full sentences and use words associated with being "reliable" according to the model. As "reliable" and "unrealiable" are often associate with "real" and "fake" - we must point out that this model is not intended to reveal if something is "real" or not, as a statement at one point in time might be false, and a moment later be "real" or "true". A computer model cannot decipher "reality"... yet.</h6></div>
        <div class="col-12"><h6 class="centered"><a href="about.html#top">BACK TO TOP</a><br><br></h6></div>
        
        <div class="col-12">
            <br>
            <h3 class="centered">Data</h3>
            <hr>
            <h6 class="centered"><a style="color: rgb(11, 135, 207)" href="https://www.kaggle.com/c/fake-news/data" target="_blank">kaggle.com | FAKE-NEWS</a></h6>
            <hr>
         </div>

    </div>
</div>

<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>


</body>

</html>
